{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60abf039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2  # converting image into array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c43fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 128\n",
    "image_height  = 128\n",
    "image_size = (image_height,image_width)\n",
    "image_channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eea2506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.listdir(r\"C:\\Users\\INDIA\\Documents\\Jupyter Files\\Dog vs Cat image CNN\\train\")\n",
    "categories = []\n",
    "\n",
    "for f_name in filename:\n",
    "    category = f_name.split(\".\")[0]\n",
    "    if category =='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c50448",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Filename': filename , 'Category':categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc4e45cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>dog.9995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>dog.9996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>dog.9997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>dog.9998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>dog.9999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename  Category\n",
       "0         cat.0.jpg         0\n",
       "1         cat.1.jpg         0\n",
       "2        cat.10.jpg         0\n",
       "3       cat.100.jpg         0\n",
       "4      cat.1000.jpg         0\n",
       "...             ...       ...\n",
       "24995  dog.9995.jpg         1\n",
       "24996  dog.9996.jpg         1\n",
       "24997  dog.9997.jpg         1\n",
       "24998  dog.9998.jpg         1\n",
       "24999  dog.9999.jpg         1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "124b9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense,Activation,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ca8410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(5,5),activation = 'relu' , input_shape = (128,128,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2) , strides = 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(5,5),activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2) , strides = 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5),activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2) , strides = 2))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2,activation = 'softmax'))\n",
    "          \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'rmsprop' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0292217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 124, 124, 32)      2432      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 124, 124, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 62, 62, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 58, 58, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 58, 58, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 29, 29, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 29, 29, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 25, 25, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 25, 25, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               9437696   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,700,290\n",
      "Trainable params: 9,698,818\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2418b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc' , patience = 2 , verbose = 1 , factor = 0.5 , min_lr = 0.000010)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1684904",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Category\"] = data[\"Category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(data , test_size = 0.2,random_state = 42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "204d15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 r\"C:\\Users\\INDIA\\Documents\\Jupyter Files\\Dog vs Cat image CNN\\train\",\n",
    "                                                    x_col='Filename',y_col='Category',\n",
    "                                                 target_size=image_size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a35b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "     r\"C:\\Users\\INDIA\\Documents\\Jupyter Files\\Dog vs Cat image CNN\\train\", \n",
    "    x_col='Filename',\n",
    "    y_col='Category',\n",
    "    target_size=image_size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "test_data = train_datagen.flow_from_dataframe(tr_df,\n",
    "                                        directory=r\"C:\\Users\\INDIA\\Documents\\Jupyter Files\\Dog vs Cat image CNN\\test1\",\n",
    "                                        x_col='Filename',\n",
    "                                        y_col='Category',\n",
    "                                        class_mode='categorical',\n",
    "                                        target_size=image_size,\n",
    "                                        shuffle=True,\n",
    "                                        seed=17  \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63ee3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA\\AppData\\Local\\Temp/ipykernel_14404/2528005629.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333/1333 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.6336WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 865s 649ms/step - loss: 0.6737 - accuracy: 0.6336 - val_loss: 0.7585 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.7248WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 880s 660ms/step - loss: 0.5478 - accuracy: 0.7248 - val_loss: 0.9730 - val_accuracy: 0.6158 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.7665WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 911s 684ms/step - loss: 0.4908 - accuracy: 0.7665 - val_loss: 1.2231 - val_accuracy: 0.6470 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7890WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 939s 704ms/step - loss: 0.4537 - accuracy: 0.7890 - val_loss: 0.7436 - val_accuracy: 0.6707 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8091WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 921s 691ms/step - loss: 0.4228 - accuracy: 0.8091 - val_loss: 0.6244 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.8231WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 936s 702ms/step - loss: 0.3951 - accuracy: 0.8231 - val_loss: 0.3110 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8332WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 966s 724ms/step - loss: 0.3775 - accuracy: 0.8332 - val_loss: 0.3604 - val_accuracy: 0.8468 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8393WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 943s 707ms/step - loss: 0.3624 - accuracy: 0.8393 - val_loss: 0.4199 - val_accuracy: 0.8084 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8452WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 893s 670ms/step - loss: 0.3539 - accuracy: 0.8452 - val_loss: 0.4082 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8507WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 897s 673ms/step - loss: 0.3458 - accuracy: 0.8507 - val_loss: 0.3538 - val_accuracy: 0.8679 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
